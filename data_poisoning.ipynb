{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-18T01:32:11.581988Z","iopub.status.busy":"2023-04-18T01:32:11.580791Z","iopub.status.idle":"2023-04-18T01:32:11.589915Z","shell.execute_reply":"2023-04-18T01:32:11.588485Z","shell.execute_reply.started":"2023-04-18T01:32:11.581921Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow import expand_dims\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:11.592427Z","iopub.status.busy":"2023-04-18T01:32:11.592064Z","iopub.status.idle":"2023-04-18T01:32:11.602918Z","shell.execute_reply":"2023-04-18T01:32:11.601835Z","shell.execute_reply.started":"2023-04-18T01:32:11.592393Z"},"trusted":true},"outputs":[],"source":["# Load the dataset\n","train_dir = '\"/Users/camrenlandry/Schoolwork/Year4Sem2/AI/project/AI_Data_Poisoning/chest_xray/train'\n","test_dir = '/Users/camrenlandry/Schoolwork/Year4Sem2/AI/project/AI_Data_Poisoning/chest_xray/test'\n","num_classes = 2\n","batch_size = 16"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:11.604936Z","iopub.status.busy":"2023-04-18T01:32:11.604535Z","iopub.status.idle":"2023-04-18T01:32:11.618290Z","shell.execute_reply":"2023-04-18T01:32:11.616941Z","shell.execute_reply.started":"2023-04-18T01:32:11.604897Z"},"trusted":true},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:11.621452Z","iopub.status.busy":"2023-04-18T01:32:11.621057Z","iopub.status.idle":"2023-04-18T01:32:13.199738Z","shell.execute_reply":"2023-04-18T01:32:13.198449Z","shell.execute_reply.started":"2023-04-18T01:32:11.621415Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '\"/Users/camrenlandry/Schoolwork/Year4Sem2/AI/project/AI_Data_Poisoning/chest_xray/train'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m      9\u001b[0m     test_dir,\n\u001b[1;32m     10\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[1;32m     11\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     12\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n","File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py:1650\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1563'>1564</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1564'>1565</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1565'>1566</a>\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1579'>1580</a>\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1580'>1581</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1581'>1582</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1582'>1583</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1583'>1584</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1647'>1648</a>\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1648'>1649</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1649'>1650</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1650'>1651</a>\u001b[0m         directory,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1651'>1652</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1652'>1653</a>\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1653'>1654</a>\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1654'>1655</a>\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1655'>1656</a>\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1656'>1657</a>\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1657'>1658</a>\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1658'>1659</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1659'>1660</a>\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1660'>1661</a>\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1661'>1662</a>\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1662'>1663</a>\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1663'>1664</a>\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1664'>1665</a>\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1665'>1666</a>\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1666'>1667</a>\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1667'>1668</a>\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[1;32m   <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=1668'>1669</a>\u001b[0m     )\n","File \u001b[0;32m~/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=560'>561</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m    <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=561'>562</a>\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[0;32m--> <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=562'>563</a>\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[1;32m    <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=563'>564</a>\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    <a href='file:///Users/camrenlandry/opt/anaconda3/envs/tensorflow_env/lib/python3.9/site-packages/keras/preprocessing/image.py?line=564'>565</a>\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\"/Users/camrenlandry/Schoolwork/Year4Sem2/AI/project/AI_Data_Poisoning/chest_xray/train'"]}],"source":["train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(150, 150),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(150, 150),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:13.202178Z","iopub.status.busy":"2023-04-18T01:32:13.201573Z","iopub.status.idle":"2023-04-18T01:32:13.359893Z","shell.execute_reply":"2023-04-18T01:32:13.358365Z","shell.execute_reply.started":"2023-04-18T01:32:13.202133Z"},"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes, activation='softmax'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:13.362474Z","iopub.status.busy":"2023-04-18T01:32:13.361996Z","iopub.status.idle":"2023-04-18T01:32:13.375549Z","shell.execute_reply":"2023-04-18T01:32:13.374214Z","shell.execute_reply.started":"2023-04-18T01:32:13.362423Z"},"trusted":true},"outputs":[],"source":["model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=Adam(learning_rate=1e-4),\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:32:13.377422Z","iopub.status.busy":"2023-04-18T01:32:13.376972Z","iopub.status.idle":"2023-04-18T01:42:20.134528Z","shell.execute_reply":"2023-04-18T01:42:20.133120Z","shell.execute_reply.started":"2023-04-18T01:32:13.377385Z"},"trusted":true},"outputs":[],"source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=3,\n","    validation_data=test_generator,\n","    validation_steps=test_generator.samples // batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:42:20.137691Z","iopub.status.busy":"2023-04-18T01:42:20.137170Z","iopub.status.idle":"2023-04-18T01:42:40.868818Z","shell.execute_reply":"2023-04-18T01:42:40.867473Z","shell.execute_reply.started":"2023-04-18T01:42:20.137638Z"},"trusted":true},"outputs":[],"source":["scores = model.evaluate(\n","    test_generator,\n","    steps=test_generator.samples // batch_size\n",")\n","\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:42:40.873586Z","iopub.status.busy":"2023-04-18T01:42:40.872943Z","iopub.status.idle":"2023-04-18T01:42:41.311334Z","shell.execute_reply":"2023-04-18T01:42:41.309825Z","shell.execute_reply.started":"2023-04-18T01:42:40.873547Z"},"trusted":true},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# plot the training and validation accuracy over time\n","plt.figure()\n","plt.plot(epochs, acc, 'bo', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","# plot the training and validation loss over time\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:42:41.313102Z","iopub.status.busy":"2023-04-18T01:42:41.312693Z","iopub.status.idle":"2023-04-18T01:42:41.478158Z","shell.execute_reply":"2023-04-18T01:42:41.476962Z","shell.execute_reply.started":"2023-04-18T01:42:41.313062Z"},"trusted":true},"outputs":[],"source":["# Use the trained model to predict the class of new images\n","new_image_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person101_bacteria_485.jpeg'\n","\n","img = load_img(\n","    new_image_path,\n","    target_size=(150, 150)\n",")\n","\n","img_array = img_to_array(img)\n","img_array = expand_dims(img_array, 0) / 255.0\n","\n","predictions = model.predict(img_array)\n","\n","#if np.argmax(predictions) == 0:\n","if predictions[0][0] > predictions[0][1]:\n","    print('The X-ray is of a normal chest')\n","else:\n","    print('The X-ray is of a chest with a pneumonia')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T01:42:41.480025Z","iopub.status.busy":"2023-04-18T01:42:41.479646Z","iopub.status.idle":"2023-04-18T01:42:42.986239Z","shell.execute_reply":"2023-04-18T01:42:42.985270Z","shell.execute_reply.started":"2023-04-18T01:42:41.479990Z"},"trusted":true},"outputs":[],"source":["# set the path to the folder containing images\n","folder_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/val'\n","\n","# loop through the sub-folders (normal and pneumonia)\n","for sub_folder in ['NORMAL', 'PNEUMONIA']:\n","    sub_folder_path = os.path.join(folder_path, sub_folder)\n","    \n","    # loop through all the images in the sub-folder\n","    for filename in os.listdir(sub_folder_path):\n","        \n","        # load the image and preprocess it\n","        img_path = os.path.join(sub_folder_path, filename)\n","        img = load_img(\n","            img_path,\n","            target_size=(150, 150)\n","        )\n","        img_array = img_to_array(img)\n","        img_array = expand_dims(img_array, 0) / 255.0\n","        \n","        # make the prediction\n","        predictions = model.predict(img_array)\n","        if predictions[0][0] > predictions[0][1]:\n","            predicted_class = 'normal'\n","        else:\n","            predicted_class = 'pneumonia'\n","        \n","        # print the prediction and actual label for the image\n","        print('Prediction: {}, Actual: {}'.format(predicted_class, sub_folder))\n","        \n","        # display the image\n","        #plt.imshow(img)\n","        #plt.title('Prediction: {}, Actual: {}'.format(predicted_class, sub_folder))\n","        #plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
